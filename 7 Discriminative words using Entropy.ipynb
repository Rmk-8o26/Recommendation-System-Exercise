{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective : Learning the process of identifying most discriminative words using Entropy\n",
    "\n",
    "## Question :\n",
    "### 1. Create a hypothetical document data set consisting of 25 documents and 75 keywords assuming there are four possible ratings and the keywords have frequencies 0,1, 2,3,4\n",
    "### 2. Print the indices of the first 5 most discriminative words\n",
    "### 3. Print the TFD corresponding the the discriminative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, ..., 2, 0, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_docs=25 # number of documents\n",
    "n_kwds=75 # number of keywords in each document\n",
    "n_rts=4 # number of possible ratings\n",
    "k=n_docs*n_kwds # total number of elements in the TDF matrix  (Term-Document-Frequency matrix)\n",
    "sim_1d=np.random.choice(5, k) # gives 80 randomly obtained numbers from 0,1,2,3,4\n",
    "sim_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 0, ..., 4, 2, 2],\n",
       "       [3, 0, 4, ..., 0, 1, 3],\n",
       "       [3, 2, 3, ..., 1, 4, 0],\n",
       "       ...,\n",
       "       [3, 2, 3, ..., 3, 0, 1],\n",
       "       [2, 3, 2, ..., 3, 2, 4],\n",
       "       [3, 2, 1, ..., 2, 0, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_d2=sim_1d.reshape(n_docs,n_kwds) # coversion of 1d-frequencies to matrix form\n",
    "sim_d2 # displaying the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 1, 3, 0, 0, 0, 2, 0, 3, 1, 0, 2, 3, 2, 0, 3, 3, 1, 2, 3,\n",
       "       2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ratings=np.random.choice(n_rts,n_docs)\n",
    "sim_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Entropies\n",
    "### Creation of 1-d array to store GI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et=np.zeros(n_kwds)  # initialized an array for storing gini indices\n",
    "et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropies are [1.27703426 1.27703426 1.01140426 1.32088834 1.32966135 1.01140426\n",
      " 1.35178399 1.32966135 1.32966135 1.27703426 1.33217904 1.27703426\n",
      " 1.35178399 1.27703426 1.27703426 1.32966135 1.33217904 1.32966135\n",
      " 1.05492017 1.35178399 1.35178399 1.35178399 1.32966135 1.24245332\n",
      " 1.32966135 1.33217904 1.27703426 1.35178399 1.35178399 1.35178399\n",
      " 1.07899221 1.01140426 1.32966135 1.32966135 1.01140426 1.07899221\n",
      " 1.32088834 1.27703426 1.27703426 1.32966135 1.24245332 1.24245332\n",
      " 1.27703426 1.05492017 1.32966135 1.33217904 1.03972077 1.32966135\n",
      " 1.05492017 1.27703426 1.01140426 1.27703426 1.35178399 1.27703426\n",
      " 1.32088834 1.27703426 1.35178399 1.32966135 1.32088834 1.35178399\n",
      " 1.35178399 1.03972077 1.01140426 1.01140426 1.35178399 1.32088834\n",
      " 1.35178399 1.35178399 1.27703426 1.07899221 1.33217904 1.27703426\n",
      " 1.32966135 1.32088834 1.27703426]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for j in range(n_kwds): # Running through the columns\n",
    "    doc_list=[] # initialization for every keyword to store the indices of documents\n",
    "    for i in range(8): # Running throug the rows\n",
    "        if (sim_d2[i,j]!=0): # checking the occurrence of  the jth keyword in ith document\n",
    "            doc_list.append(i)\n",
    "    #print('keyword ...',j) # todispplay the keyword index\n",
    "    # #print(doc_list) # to display the list of documents\n",
    "    # #print(sim_ratings[doc_list]) # to display the corresponding rating\n",
    "    rt_arr=sim_ratings[doc_list]\n",
    "    u,c=np.unique(rt_arr,return_counts=True)\n",
    "    #print('Frequencies are',c)\n",
    "    p=c/sum(c)\n",
    "    #print('Probabilities are',p)\n",
    "    et[j]=-sum(p*np.log(p))\n",
    "  # print('----------------')\n",
    "print('Entropies are',et)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the first 5 most discriminative keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the  first 5 most discriminative keywords are [ 2 34  5 63 62]\n"
     ]
    }
   ],
   "source": [
    "indices=np.argsort(et) # indices of the sorted values\n",
    "print('Indices of the  first 5 most discriminative keywords are',  indices[0:5] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the TFD for the most discriminative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 1 0 1]\n",
      " [4 1 0 3 1]\n",
      " [3 0 1 2 0]\n",
      " [0 0 0 3 0]\n",
      " [3 2 3 0 1]\n",
      " [1 2 4 3 2]\n",
      " [3 4 1 3 2]\n",
      " [1 4 3 4 2]\n",
      " [1 0 2 2 1]\n",
      " [1 2 1 1 3]\n",
      " [2 4 4 3 2]\n",
      " [4 3 3 0 2]\n",
      " [3 2 1 1 4]\n",
      " [1 0 3 3 4]\n",
      " [1 0 4 0 0]\n",
      " [4 0 3 2 4]\n",
      " [2 3 4 1 3]\n",
      " [0 0 4 0 2]\n",
      " [1 3 3 3 3]\n",
      " [4 4 3 3 2]\n",
      " [4 0 4 1 0]\n",
      " [1 4 2 2 0]\n",
      " [3 0 4 3 3]\n",
      " [2 4 4 1 3]\n",
      " [1 1 4 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(sim_d2[:,indices[0:5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "### The indices of the first 5 most discriminative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
