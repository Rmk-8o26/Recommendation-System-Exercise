{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : Learning the implementation of CBRSusing TF-IDTF matrix\n",
    "## Problem\n",
    "### 1. Create the TF-IDTF matrix for the music recommender example data given below:\n",
    "#### sg1='drums,guitar,beat'\n",
    "#### sg2='drums,guitar,orchestra'\n",
    "#### sg3='guitar,beat'\n",
    "#### sg4='classical,symphony,orchestra'\n",
    "#### sg5='guitar,classical,orchestra'\n",
    "#### sg6='classical,symphony'\n",
    "#### whose ratings are 0,1,0,1,0,0\n",
    "\n",
    "### 2. Reduce the dimension using PCA\n",
    "\n",
    "### 3. Carryout inline prediction using Logistic regression\n",
    "\n",
    "### Step 1: Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg1='drums,guitar,beat,guitar,guitar,beats'\n",
    "sg2='drums,guitar,orchestra'\n",
    "sg3='guitar,beat'\n",
    "sg4='classical,symphony,orchestra'\n",
    "sg5='guitar,classical,orchestra'\n",
    "sg6='classical,symphony'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Merge the documents to a create a single corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drums,guitar,beat,guitar,guitar,beats',\n",
       " 'drums,guitar,orchestra',\n",
       " 'guitar,beat',\n",
       " 'classical,symphony,orchestra',\n",
       " 'guitar,classical,orchestra',\n",
       " 'classical,symphony']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[sg1,sg2,sg3,sg4,sg5,sg6]\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: TF-IDTF matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.34926005140142785\n",
      "  (0, 4)\t0.7580418492355107\n",
      "  (0, 0)\t0.34926005140142785\n",
      "  (0, 1)\t0.42591946163300803\n",
      "  (1, 3)\t0.668719891595794\n",
      "  (1, 4)\t0.48380155055600843\n",
      "  (1, 5)\t0.5645792825314363\n",
      "  (2, 4)\t0.5861569567966913\n",
      "  (2, 0)\t0.8101975203608325\n",
      "  (3, 5)\t0.5420919460564738\n",
      "  (3, 2)\t0.5420919460564738\n",
      "  (3, 6)\t0.642084608164228\n",
      "  (4, 4)\t0.5182242665631911\n",
      "  (4, 5)\t0.6047493735197427\n",
      "  (4, 2)\t0.6047493735197427\n",
      "  (5, 2)\t0.6451024322949592\n",
      "  (5, 6)\t0.764096101185661\n"
     ]
    }
   ],
   "source": [
    "result=tfidf.fit_transform(corpus)\n",
    "print(result) # viewing the sparse representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34926005 0.42591946 0.         0.34926005 0.75804185 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.66871989 0.48380155 0.56457928\n",
      "  0.        ]\n",
      " [0.81019752 0.         0.         0.         0.58615696 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.54209195 0.         0.         0.54209195\n",
      "  0.64208461]\n",
      " [0.         0.         0.60474937 0.         0.51822427 0.60474937\n",
      "  0.        ]\n",
      " [0.         0.         0.64510243 0.         0.         0.\n",
      "  0.7640961 ]]\n"
     ]
    }
   ],
   "source": [
    "#print(tfidf.vocabulary_)\n",
    "print(result.toarray()) # to see the matrix representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF_IDTF matrix creation for the the training_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1='classical'\n",
    "t2='drums,beat'\n",
    "corpus=[sg1,sg2,sg3,sg4,sg5,sg6,t1,t2]\n",
    "#corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.3038587352347985\n",
      "  (0, 4)\t0.7992514181378093\n",
      "  (0, 0)\t0.3038587352347985\n",
      "  (0, 1)\t0.42016295487312805\n",
      "  (1, 3)\t0.600978201166947\n",
      "  (1, 4)\t0.5269254249362817\n",
      "  (1, 5)\t0.600978201166947\n",
      "  (2, 4)\t0.6592621372425836\n",
      "  (2, 0)\t0.7519131827533952\n",
      "  (3, 5)\t0.5668934226488676\n",
      "  (3, 2)\t0.49704058656839417\n",
      "  (3, 6)\t0.6569493912480618\n",
      "  (4, 4)\t0.5504130215007531\n",
      "  (4, 5)\t0.627766685580577\n",
      "  (4, 2)\t0.5504130215007531\n",
      "  (5, 2)\t0.603357526680706\n",
      "  (5, 6)\t0.7974708113766555\n",
      "  (6, 2)\t1.0\n",
      "  (7, 3)\t0.7071067811865475\n",
      "  (7, 0)\t0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "result=tfidf.fit_transform(corpus)\n",
    "#print(result)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47945672, 0.6845736 , 0.82897142, 0.93613894, 0.99091653,\n",
       "       0.9994026 , 1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "X=result.toarray()\n",
    "pca=PCA()\n",
    "pca.fit(X)\n",
    "np.cumsum(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60080536,  0.10209487],\n",
       "       [-0.3485942 ,  0.48596018],\n",
       "       [-0.59051593, -0.18790507],\n",
       "       [ 0.62234168,  0.09687855],\n",
       "       [ 0.1710981 ,  0.5393439 ],\n",
       "       [ 0.68263317, -0.31748088],\n",
       "       [ 0.59793697, -0.17669488],\n",
       "       [-0.53409443, -0.54219665]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_red=pca.transform(X)\n",
    "X_red\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of training data and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=result.toarray()\n",
    "X_train=X_red[0:6,:]\n",
    "y=np.array([0,1,0,1,0,0])\n",
    "y=np.transpose(y)\n",
    "print(X_train.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514977\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 11 Sep 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.1909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:16:29</td>     <th>  Log-Likelihood:    </th> <td> -3.0899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -3.8191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.4823</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.3470</td> <td>    1.304</td> <td>   -1.033</td> <td> 0.302</td> <td>   -3.903</td> <td>    1.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.4767</td> <td>    2.190</td> <td>    0.674</td> <td> 0.500</td> <td>   -2.816</td> <td>    5.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.4893</td> <td>    3.518</td> <td>    0.992</td> <td> 0.321</td> <td>   -3.407</td> <td>   10.385</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &        6    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &        3    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Date:}            & Wed, 11 Sep 2024 & \\textbf{  Pseudo R-squ.:     } &   0.1909    \\\\\n",
       "\\textbf{Time:}            &     13:16:29     & \\textbf{  Log-Likelihood:    } &   -3.0899   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -3.8191   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &   0.4823    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -1.3470  &        1.304     &    -1.033  &         0.302        &       -3.903    &        1.209     \\\\\n",
       "\\textbf{x1}    &       1.4767  &        2.190     &     0.674  &         0.500        &       -2.816    &        5.770     \\\\\n",
       "\\textbf{x2}    &       3.4893  &        3.518     &     0.992  &         0.321        &       -3.407    &       10.385     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                    6\n",
       "Model:                          Logit   Df Residuals:                        3\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 11 Sep 2024   Pseudo R-squ.:                  0.1909\n",
       "Time:                        13:16:29   Log-Likelihood:                -3.0899\n",
       "converged:                       True   LL-Null:                       -3.8191\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.4823\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.3470      1.304     -1.033      0.302      -3.903       1.209\n",
       "x1             1.4767      2.190      0.674      0.500      -2.816       5.770\n",
       "x2             3.4893      3.518      0.992      0.321      -3.407      10.385\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_tr=sm.add_constant(X_train)\n",
    "#print(X_tr.shape)\n",
    "model=sm.Logit(y,X_tr).fit()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.60080536,  0.10209487],\n",
       "       [ 1.        , -0.3485942 ,  0.48596018],\n",
       "       [ 1.        , -0.59051593, -0.18790507],\n",
       "       [ 1.        ,  0.62234168,  0.09687855],\n",
       "       [ 1.        ,  0.1710981 ,  0.5393439 ],\n",
       "       [ 1.        ,  0.68263317, -0.31748088]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inline Predicted values are [0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Inline Predicted values are',np.round(model.predict(X_tr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion : Outcomes will be Dislike,Dislike,Dislike,Dislike,Like and Dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
